# requirements.txt for LLM Orchestration Service

fastapi>=0.100.0 # Core FastAPI framework
uvicorn[standard]>=0.20.0 # ASGI server for FastAPI (standard includes websockets, http-tools)
pydantic>=2.0.0 # Data validation and settings management

# LLM Provider Libraries (add specific ones you use)
openai>=1.3.0       # Ensure a recent version for vision/audio features
google-generativeai>=0.5.0 # Specify a version known to work with GenerativeModel and configure
# google-cloud-aiplatform # For Google Vertex AI
# huggingface_hub     # For Hugging Face Inference API
# transformers        # For local Hugging Face models (if used)

# Utility Libraries
tenacity>=8.0.0     # For retries
python-dotenv

# Caching (optional, choose one or implement custom)
# fastapi-cache2[redis] # If using Redis with fastapi-cache2
# redis               # If using Redis directly

# Configuration file format (if not just JSON/env)
# pyyaml            # If using YAML for config files

# For development (optional, could be in a dev-requirements.txt)
# httpx             # For testing FastAPI apps (async client)
# pytest
# pytest-asyncio

python-multipart